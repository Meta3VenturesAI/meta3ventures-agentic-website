#!/bin/bash

# Meta3Ventures Local Setup Demonstration
# This script demonstrates the complete local testing environment setup

set -e

echo "ğŸ¬ Meta3Ventures Local Testing Environment Demo"
echo "=============================================="

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

print_header() {
    echo -e "\n${CYAN}ğŸ“‹ $1${NC}"
    echo "----------------------------------------"
}

print_step() {
    echo -e "${BLUE}ğŸ”§ $1${NC}"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

print_info() {
    echo -e "${MAGENTA}â„¹ï¸  $1${NC}"
}

# Check if we're in the right directory
if [ ! -f "setup-local-testing.sh" ]; then
    echo -e "${RED}âŒ Please run this script from the project root directory${NC}"
    exit 1
fi

print_header "Environment Analysis"
print_info "Current directory: $(pwd)"
print_info "Node.js version: $(node --version)"
print_info "Docker version: $(docker --version)"
print_info "Docker Compose version: $(docker-compose --version)"

print_header "Setup Files Created"
print_success "âœ… docker-compose.local.yml - LLM providers configuration"
print_success "âœ… project/env.local - Environment variables template"
print_success "âœ… project/local-dev-server.js - Netlify functions replica"
print_success "âœ… project/test-full-platform.cjs - Comprehensive test suite"
print_success "âœ… setup-local-testing.sh - Automated setup script"
print_success "âœ… cleanup-local-testing.sh - Cleanup script"
print_success "âœ… LOCAL_TESTING_GUIDE.md - Complete documentation"

print_header "LLM Providers Configured"
print_info "ğŸ³ Ollama (Local LLM Server)"
print_info "   â€¢ Container: meta3-ollama"
print_info "   â€¢ Port: 11434"
print_info "   â€¢ Models: llama3.2:3b, llama3.1:8b, mistral:7b, codellama:7b"

print_info "ğŸš€ vLLM (High-performance LLM Serving)"
print_info "   â€¢ Container: meta3-vllm"
print_info "   â€¢ Port: 8000"
print_info "   â€¢ Model: llama-2-7b-chat"

print_info "ğŸ  LocalAI (Self-hosted OpenAI Compatible API)"
print_info "   â€¢ Container: meta3-localai"
print_info "   â€¢ Port: 8080"
print_info "   â€¢ Model: ggml-gpt4all-j"

print_info "ğŸ§  DeepSeek (Advanced AI)"
print_info "   â€¢ Proxy: meta3-deepseek-proxy"
print_info "   â€¢ Port: 8082"
print_info "   â€¢ Model: deepseek-chat"

print_info "ğŸ¤– Grok (xAI's AI Model)"
print_info "   â€¢ Proxy: meta3-grok-proxy"
print_info "   â€¢ Port: 8081"
print_info "   â€¢ Model: grok-beta"

print_header "Local Development Server Features"
print_success "âœ… Replicates Netlify functions"
print_success "âœ… Agent proxy endpoint"
print_success "âœ… Health check endpoint"
print_success "âœ… Provider status monitoring"
print_success "âœ… CORS configuration"
print_success "âœ… Security headers (replicating netlify.toml)"

print_header "Test Suite Capabilities"
print_success "âœ… Server health tests"
print_success "âœ… LLM provider availability tests"
print_success "âœ… Agent proxy functionality tests"
print_success "âœ… Vite development server tests"
print_success "âœ… Build system tests"
print_success "âœ… Environment variable validation"
print_success "âœ… Agent system component tests"

print_header "Quick Start Commands"
print_info "ğŸš€ Complete Setup:"
print_info "   ./setup-local-testing.sh"
print_info ""
print_info "ğŸ§ª Run Tests:"
print_info "   cd project && npm run test:full-platform"
print_info ""
print_info "ğŸŒ Access Points:"
print_info "   â€¢ Main App: http://localhost:5173"
print_info "   â€¢ Admin Dashboard: http://localhost:5173/admin"
print_info "   â€¢ Local Dev Server: http://localhost:3001"
print_info "   â€¢ Provider Status: http://localhost:3001/api/providers/status"
print_info ""
print_info "ğŸ§¹ Cleanup:"
print_info "   ./cleanup-local-testing.sh"

print_header "Environment Variables Required"
print_warning "For full functionality, update these in project/.env.local:"
print_info "   â€¢ VITE_HUGGINGFACE_API_KEY"
print_info "   â€¢ VITE_DEEPSEEK_API_KEY"
print_info "   â€¢ VITE_GROK_API_KEY"
print_info "   â€¢ VITE_FORMSPREE_*_KEY"
print_info "   â€¢ VITE_SUPABASE_*"
print_info "   â€¢ VITE_SENTRY_DSN"

print_header "System Requirements"
print_info "ğŸ’» Minimum Requirements:"
print_info "   â€¢ 8GB RAM (for multiple LLM providers)"
print_info "   â€¢ 20GB disk space (for model downloads)"
print_info "   â€¢ Docker & Docker Compose"
print_info "   â€¢ Node.js 18+"

print_header "What This Setup Provides"
print_success "âœ… Complete Netlify environment replication"
print_success "âœ… Full LLM provider support (Ollama, vLLM, LocalAI, DeepSeek, Grok)"
print_success "âœ… Real agent system testing"
print_success "âœ… Comprehensive test suite"
print_success "âœ… Production-ready validation"
print_success "âœ… Easy setup and cleanup"
print_success "âœ… Complete documentation"

print_header "Next Steps"
print_info "1. Run the setup script: ./setup-local-testing.sh"
print_info "2. Update API keys in project/.env.local"
print_info "3. Test the platform: cd project && npm run test:full-platform"
print_info "4. Access the application: http://localhost:5173"
print_info "5. Test admin functionality: http://localhost:5173/admin"

echo -e "\n${GREEN}ğŸ‰ Meta3Ventures Local Testing Environment is ready!${NC}"
echo -e "${CYAN}ğŸ“š See LOCAL_TESTING_GUIDE.md for detailed instructions${NC}"
echo -e "${YELLOW}ğŸš€ Run ./setup-local-testing.sh to start testing!${NC}"

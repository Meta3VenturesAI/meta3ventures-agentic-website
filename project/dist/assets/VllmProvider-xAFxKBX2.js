var e=Object.defineProperty,t=(t,r,s)=>((t,r,s)=>r in t?e(t,r,{enumerable:!0,configurable:!0,writable:!0,value:s}):t[r]=s)(t,"symbol"!=typeof r?r+"":r,s);import{p as r}from"./AgentAuthGuard-BSe8gvOH.js";import"./supabase-BhLMWRjL.js";import"./index-CIzmM8sf.js";import"./react-vendor-eVk5PToZ.js";import"./router-Bf3h2-TO.js";import"./icons-CrFATGyQ.js";import"./ui-vendor-BqqUpcLC.js";class s{constructor(){t(this,"id","vllm"),t(this,"name","vLLM (Open Source)"),t(this,"baseUrl"),t(this,"defaultModel"),this.baseUrl="http://localhost:8000/v1",this.defaultModel="llama-3-8b-instruct"}async isAvailable(){try{return(await fetch(`${this.baseUrl}/models`,{method:"GET",headers:{"Content-Type":"application/json"}})).ok}catch(e){return!1}}async generate(e){const t=e.model||this.defaultModel;try{const r=await fetch(`${this.baseUrl}/chat/completions`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({model:t,messages:e.messages,temperature:e.temperature??.7,max_tokens:e.maxTokens??1024,top_p:e.topP??.9,stream:!1})});if(!r.ok){const e=await r.text();throw new Error(`vLLM error: ${r.status} ${e}`)}const s=await r.json(),o=s.choices?.[0]?.message?.content;return o?.trim()||""}catch(r){throw new Error(`Failed to generate response: ${r instanceof Error?r.message:"Unknown error"}`)}}}const o=new s;r.register(o);export{s as VllmProvider};
